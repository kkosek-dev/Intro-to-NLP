{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "335ab3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Perceptron, SGDClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c22d363",
   "metadata": {},
   "source": [
    "# NLP Classifiers from Scraped Product Reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0ef54ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Methods\n",
    "def evaluate_predictions(predictions):\n",
    "    counter=0\n",
    "    for pred in predictions:\n",
    "        print(f'The sentence \"{sentences[counter]}\" is {pred}')\n",
    "        counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "839f49d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2/7/2024</td>\n",
       "      <td>Unfortunately the tv fell on me after purchasi...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11/1/2023</td>\n",
       "      <td>I love Vizio that’s always my go to brand I ha...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11/22/2023</td>\n",
       "      <td>I ordered a Vizio 50\" Class V-Series 4L UHD LE...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/5/2023</td>\n",
       "      <td>It didn't work right out of the box. Nothing b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12/24/2023</td>\n",
       "      <td>I ordered  75” Vizio TV and just put it up, bu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1141</th>\n",
       "      <td>11/22/2023</td>\n",
       "      <td>Absolutely love this picture is so clear sound...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1142</th>\n",
       "      <td>11/6/2023</td>\n",
       "      <td>I am satisfied with my Vizio 50 inch . Perfect...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1143</th>\n",
       "      <td>10/28/2023</td>\n",
       "      <td>GREAT CUSTOMER SERVICE!!!</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1144</th>\n",
       "      <td>12/9/2023</td>\n",
       "      <td>Gave as a gift. She had one previously.</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1145</th>\n",
       "      <td>12/8/2023</td>\n",
       "      <td>Tv is very good. Easy to use, easy to hook up....</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4068 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            date                                               text  stars\n",
       "0       2/7/2024  Unfortunately the tv fell on me after purchasi...      1\n",
       "1      11/1/2023  I love Vizio that’s always my go to brand I ha...      1\n",
       "2     11/22/2023  I ordered a Vizio 50\" Class V-Series 4L UHD LE...      1\n",
       "3      12/5/2023  It didn't work right out of the box. Nothing b...      1\n",
       "4     12/24/2023  I ordered  75” Vizio TV and just put it up, bu...      1\n",
       "...          ...                                                ...    ...\n",
       "1141  11/22/2023  Absolutely love this picture is so clear sound...      5\n",
       "1142   11/6/2023  I am satisfied with my Vizio 50 inch . Perfect...      5\n",
       "1143  10/28/2023                          GREAT CUSTOMER SERVICE!!!      5\n",
       "1144   12/9/2023            Gave as a gift. She had one previously.      5\n",
       "1145   12/8/2023  Tv is very good. Easy to use, easy to hook up....      5\n",
       "\n",
       "[4068 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Raw data read in\n",
    "# Initialize variables\n",
    "range_ = range(1,6)\n",
    "df = pd.DataFrame()\n",
    "\n",
    "# Combine the range of starred data into one DataFrame object\n",
    "for i in range_:\n",
    "    # Read in the i-th record\n",
    "    r_df = pd.read_csv(f'data/scraped_{i}star_data.csv')\n",
    "    # Concat with master df\n",
    "    df = pd.concat([df,r_df])\n",
    "# Strip everything but the first character in the 'stars' column & convert to int\n",
    "df['stars'] = df['stars'].apply(lambda x: int(x[0]))\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c59a12d",
   "metadata": {},
   "source": [
    "# Binary Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63280657",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Binary Preprocess\n",
    "\n",
    "# Create a copy of the 'stars' column where 'stars' is equal to 5\n",
    "five = df.loc[ df['stars'] == 5 ].copy()\n",
    "# Add a new column in the length of the DataFrame with all 1s to bin 5stars\n",
    "five['bin_sent'] = pd.Series( [x/x for x in range(1,len(five)+1)] , index=five.index )\n",
    "# Create a copy of the 'stars' column where 'stars' is equal to 1\n",
    "one = df.loc[ df['stars'] == 1 ].copy()\n",
    "# Add a new column in the length of the DataFrame with all 0s to bin 1stars\n",
    "one['bin_sent'] = pd.Series( [((x/x)-1) for x in range(1,len(one)+1)] , index=one.index )\n",
    "# Concat the binary sentiment df\n",
    "pos_neg = pd.concat( [five,one] )\n",
    "\n",
    "# Separate df into data & target\n",
    "data = np.array(pos_neg['text'])\n",
    "target = np.array(pos_neg['bin_sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2219c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.3)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', MultinomialNB())\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3ee35473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.91      0.93       290\n",
      "         1.0       0.92      0.96      0.94       340\n",
      "\n",
      "    accuracy                           0.94       630\n",
      "   macro avg       0.94      0.93      0.94       630\n",
      "weighted avg       0.94      0.94      0.94       630\n",
      "\n",
      "Confusion Matrix:\n",
      "[[263  27]\n",
      " [ 13 327]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"Perceptron Model:\\n{metrics.classification_report(y_test, y_pred)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ece4d104",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"I like this product.\" is 1.0\n",
      "The sentence \"I dislike this product.\" is 1.0\n",
      "The sentence \"The product is amazing.\" is 1.0\n",
      "The sentence \"The product is terrible.\" is 0.0\n",
      "The sentence \"The world is good.\" is 1.0\n",
      "The sentence \"The world is bad.\" is 0.0\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict binary sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "evaluate_predictions(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3551d82",
   "metadata": {},
   "source": [
    "# Binned Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f3f0078",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bin Preprocess\n",
    "\n",
    "# Initialize empty column\n",
    "sent = []\n",
    "# Loop through actual df\n",
    "for i in df['stars']:\n",
    "    # Apply bin label to empty column based on value of 'stars'\n",
    "    # Greater than 3 stars = 1\n",
    "    if i > 3:\n",
    "        sent.append(1)\n",
    "    # 3 stars = 0\n",
    "    elif i == 3:\n",
    "        sent.append(0)\n",
    "    # Less than 3 stars = -1\n",
    "    else: \n",
    "        sent.append(-1)\n",
    "# Append column to master df\n",
    "df['sent'] = sent\n",
    "    \n",
    "# Separate df into data & target\n",
    "data = np.array(df['text'])\n",
    "target = np.array(df['sent'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5560bb69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.4)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          tol=None))\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6da6bb99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.73      0.86      0.79       628\n",
      "           0       0.53      0.27      0.36       306\n",
      "           1       0.81      0.86      0.83       694\n",
      "\n",
      "    accuracy                           0.75      1628\n",
      "   macro avg       0.69      0.66      0.66      1628\n",
      "weighted avg       0.73      0.75      0.73      1628\n",
      "\n",
      "Confusion Matrix:\n",
      "[[540  33  55]\n",
      " [139  82  85]\n",
      " [ 60  39 595]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"Perceptron Model:\\n{metrics.classification_report(y_test, y_pred)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "245da32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"I like this product.\" is 1\n",
      "The sentence \"I dislike this product.\" is 1\n",
      "The sentence \"The product is amazing.\" is 1\n",
      "The sentence \"The product is terrible.\" is -1\n",
      "The sentence \"The world is good.\" is 1\n",
      "The sentence \"The world is bad.\" is -1\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict binned sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "evaluate_predictions(new_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48edd2c0",
   "metadata": {},
   "source": [
    "# Categorical Sentiment Analysis Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "af31a7a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Categorical Preprocess\n",
    "\n",
    "# Separate df into data & target\n",
    "data = np.array(df['text'])\n",
    "target = np.array(df['stars'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9d5387c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Test Split\n",
    "docs_train, docs_test, y_train, y_test = train_test_split(\n",
    "    data, target, test_size=0.4)\n",
    "\n",
    "# Construct Pipeline object\n",
    "txt_clf = Pipeline(\n",
    "    [\n",
    "        ('vect', TfidfVectorizer(ngram_range=(1,2))),\n",
    "        ('clf', SGDClassifier(loss='squared_hinge', penalty='l2',\n",
    "                          alpha=1e-3, random_state=42,\n",
    "                          tol=None))\n",
    "    ]\n",
    ").fit(docs_train,y_train)\n",
    "\n",
    "# Predict from Pipeline\n",
    "y_pred = txt_clf.predict(docs_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a85eeab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Model:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.61      0.85      0.71       390\n",
      "           2       0.43      0.18      0.25       244\n",
      "           3       0.46      0.46      0.46       322\n",
      "           4       0.43      0.19      0.26       233\n",
      "           5       0.69      0.88      0.77       439\n",
      "\n",
      "    accuracy                           0.58      1628\n",
      "   macro avg       0.52      0.51      0.49      1628\n",
      "weighted avg       0.55      0.58      0.54      1628\n",
      "\n",
      "Confusion Matrix:\n",
      "[[331  15  24   4  16]\n",
      " [ 95  43  79   9  18]\n",
      " [ 74  34 147  27  40]\n",
      " [ 18   6  63  44 102]\n",
      " [ 23   3   9  19 385]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the predictions of our model\n",
    "print(f\"Perceptron Model:\\n{metrics.classification_report(y_test, y_pred)}\")\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{cm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "53e68d66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sentence \"I like this product.\" is 5\n",
      "The sentence \"I dislike this product.\" is 1\n",
      "The sentence \"The product is amazing.\" is 5\n",
      "The sentence \"The product is terrible.\" is 2\n",
      "The sentence \"The world is good.\" is 3\n",
      "The sentence \"The world is bad.\" is 3\n"
     ]
    }
   ],
   "source": [
    "# Use txt_clf to predict categorical sentiment of new sentences\n",
    "sentences = [\n",
    "    # Subjective 1st Person\n",
    "    \"I like this product.\",\n",
    "    \"I dislike this product.\",\n",
    "    # Subjective 3rd Person\n",
    "    \"The product is amazing.\",\n",
    "    \"The product is terrible.\",\n",
    "    # General 3rd person\n",
    "    \"The world is good.\",\n",
    "    \"The world is bad.\"\n",
    "]\n",
    "\n",
    "new_pred = txt_clf.predict(sentences)\n",
    "evaluate_predictions(new_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bootcampDev",
   "language": "python",
   "name": "bootcampdev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
